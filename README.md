# Project Setup and Implementation Details
# Setup Guide
pip install -r requirements.txt

Clone the GitHub Repository ||
Open VS Code with the folder ||
Open terminal and ||
    type: python app.py ||
Click on the " Running on http://127.0.0.1:5000 " ||
Now, you will see a box having placeholder written ‚Äú‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶≤‡¶ø‡¶ñ‡ßÅ‡¶®‚Äù? ||
Write your question ||
Click the ‚Äú‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‚Äù button ||
Here We Go!! üö® ||

# Used Tools, Libraries, and Packages
Flask: Lightweight web framework for serving HTML UI

EasyOCR: For extracting text from images

```pdf2image```: Converts PDF pages to images

```google-generativeai```: To access Gemini 2.5 Flash for LLM inference

```langchain```: Framework for chaining LLMs with tools (retrieval, memory, etc.)

```tiktoken```: For tokenization

```chromadb```: Local vector store for embeddings

```sentence-transformers```: Generates dense semantic embeddings

```transformers```: For advanced NLP models

```python-dotenv```: Loads environment variables like GEMINI_API_KEY

```langchain_community```: Integrates with ChromaDB and Hugging Face embeddings

```langchain-core```: Core LangChain functionalities

```re``` (regex): Custom sentence splitting (handles Bangla punctuation like |)

```os/sys```: File path access and CLI handling

```flask.request, flask.jsonify, flask.render_template```: Accepting queries, returning answers, and rendering templates

# Sample Queries and Outputs
User Question: ‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?Expected Answer: ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶ï‡ßá  

User Question: ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?Expected Answer: ‡ßß‡ß´ ‡¶¨‡¶õ‡¶∞  

User Question: ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞‡¶®‡¶æ‡¶• ‡¶†‡¶æ‡¶ï‡ßÅ‡¶∞ ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Æ ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º?Expected Answer: ‡¶ú‡ßã‡ßú‡¶æ‡¶∏‡¶æ‡¶Å‡¶ï‡ßã ‡¶ï‡¶≤‡¶ï‡¶æ‡¶§‡¶æ, ‡¶≠‡¶æ‡¶∞‡¶§

# Implementation Details
Text Extraction Method and Challenges

Method/Library: Used pytesseract with pdf2image to extract text from PDFs.  

Reason: pdf2image converts PDF pages to images, and pytesseract performs OCR to extract text, which is effective for scanned or image-based PDFs.  

Challenges:  

Formatting issues with Bangla text, especially with complex scripts and punctuation (e.g., |).  

Inconsistent font rendering in PDFs can lead to OCR errors.  

Structured content like tables or lists (e.g., ‚Äú‡¶ï‡¶¨‡¶ø ‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶ø‚Äù) often loses formatting, impacting retrieval accuracy.

# Chunking Strategy

Strategy: Custom Bangla sentence-based chunking with a character limit of ~500 characters and an optional 50-character overlap.  

Details:  

Preserves sentence boundaries in Bangla (|, ?, !).  

Ensures semantic cohesion within each chunk.  

Overlapping retains context across adjacent chunks, improving retrieval relevance.

Why it Works: Sentence-based chunking aligns with the narrative style of the content, and overlaps maintain contextual continuity, enhancing semantic retrieval.

# Embedding Model

Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 from HuggingFace.  

Reason:  

Multilingual support, effective for Bangla.  

Lightweight yet powerful for semantic embeddings.  

Widely used in production-grade RAG systems.


How it Captures Meaning: Generates dense vector representations where semantically similar texts are close in vector space. Trained on sentence-level paraphrasing tasks, it excels at capturing meaning for retrieval.

# Query and Chunk Comparison

Storage: ChromaDB as the vector store.  

Similarity Method: Cosine similarity between query and chunk embeddings.  

Reason:  

ChromaDB is lightweight, fast, and integrates seamlessly with LangChain.  

Cosine similarity is efficient for high-dimensional embeddings and widely used.

Ensuring Meaningful Comparison:  

Query and chunks are embedded using the same model, ensuring they lie in the same vector space.  

Carefully tuned chunk size preserves contextual meaning.


Handling Vague Queries:  

Vague or contextless queries may retrieve less relevant chunks due to poor semantic alignment.  

Mitigation: Improve chunking with NLP-based sentence boundary detection or use larger documents for richer context.



# Result Relevance and Improvements

Relevance: Results are generally relevant for fact-based or direct questions.  

Challenges: Structured sections (e.g., tables or lists like ‚Äú‡¶ï‡¶¨‡¶ø ‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶ø‚Äù) are poorly chunked, leading to retrieval issues.  

Potential Improvements:  

Improved Chunking: Use NLP tools or language-specific tokenizers for accurate sentence boundary detection.  

Larger Document Input: More context improves retrieval performance.  

Advanced Embeddings: Transformer-based models with attention mechanisms could better capture semantic structure, though at higher computational cost.  

Preprocessing Structured Content: Manually preprocess or differently chunk structured sections like tables or lists.




